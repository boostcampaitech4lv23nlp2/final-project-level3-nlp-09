{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from src.preprocess import image_transform\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Sampler, DataLoader\n",
    "from src.model import build_model\n",
    "from src.tokenizer import FoodTokenizer\n",
    "\n",
    "with open(\"src/model_configs/baseline.json\") as f:\n",
    "    configs = json.load(f)\n",
    "    text_cfg = configs[\"text_cfg\"]\n",
    "    vision_cfg = configs[\"vision_cfg\"]\n",
    "\n",
    "preprocess = image_transform(vision_cfg[\"image_size\"], is_train=True)\n",
    "\n",
    "\n",
    "class FoodImageDataset(Dataset):\n",
    "    def __init__(self,transforms, mode=\"train\"):\n",
    "        self.dataset_path = \"data\"\n",
    "        self.dataset_mode = \"train\" if mode == \"train\" else \"test\"\n",
    "        self.labels_info_file_name = \"labels.json\"\n",
    "        self.train_info_file_name = \"train/aihub:1.0_43_0.3_train_crop.json\"\n",
    "        self.test_info_file_name = \"test/aihub:1.0_43_0.3_train_crop.json\"\n",
    "        self.labels_file_path = os.path.join(self.dataset_path, self.labels_info_file_name)\n",
    "        self.train_file_path = os.path.join(self.dataset_path, self.train_info_file_name)\n",
    "        self.test_file_path = os.path.join(self.dataset_path, self.test_info_file_name)\n",
    "\n",
    "        self.label_data = None\n",
    "        self.train_data = None\n",
    "        self.id_to_text_dict = None\n",
    "        self.text_to_id_dict = None\n",
    "\n",
    "        if mode == \"train\":\n",
    "            self.labels, self.data = self.get_dataset(self.labels_file_path, self.train_file_path)\n",
    "        elif mode == \"test\":\n",
    "            self.labels, self.data = self.get_dataset(self.labels_file_path, self.test_file_path)\n",
    "\n",
    "        self.id_to_text_dict = self.get_id_to_text(self.labels)\n",
    "        self.text_to_id_dict = self.get_text_to_id(self.labels)\n",
    "\n",
    "        self.data = self.data\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_dataset(self, labels_file_path, data_file_path):\n",
    "        with open(labels_file_path, \"r\") as file:\n",
    "            labels = json.load(file)\n",
    "            labels = labels[\"categories\"]\n",
    "\n",
    "        with open(data_file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            data = data[\"images\"]\n",
    "\n",
    "        return labels, data\n",
    "\n",
    "    def get_id_to_text(self, label_data):\n",
    "        return {item[\"id\"]: item[\"label\"] for item in label_data}\n",
    "\n",
    "    def get_text_to_id(self, label_data):\n",
    "        return {item[\"label\"]: item[\"id\"] for item in label_data}\n",
    "\n",
    "    def transform_func(self, examples):\n",
    "        examples[\"image\"] = [self.preprocess(image) for image in examples[\"image\"]]\n",
    "        return examples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_id = self.data[idx][\"category_id\"]\n",
    "        text = self.id_to_text_dict[text_id]\n",
    "        file_name = os.path.split(self.data[idx][\"file_name\"])[-1]\n",
    "        file_path = os.path.join(self.dataset_path, self.dataset_mode, file_name)\n",
    "        image = Image.open(file_path)\n",
    "        image = self.transforms(image)\n",
    "        return text, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FoodImageDataset(preprocess, mode=\"train\")\n",
    "dset = train_dataset\n",
    "oversample = False\n",
    "seed = 42\n",
    "shuffle = True\n",
    "epoch = 0 \n",
    "\n",
    "cls = {}\n",
    "cls_class = defaultdict(list)\n",
    "\n",
    "with open(\"./food_id_to_category_id.json\") as f :\n",
    "    food_to_category = json.load(f)\n",
    "    \n",
    "food_to_category = {int(k):int(v) for k,v in food_to_category.items()}\n",
    "\n",
    "for ind, data in enumerate(dset.data):\n",
    "    label = data[\"category_id\"]\n",
    "    if label in cls:\n",
    "        cls[label].append(ind)\n",
    "    else:\n",
    "        cls[label] = [ind]\n",
    "\n",
    "for key in cls.keys():\n",
    "    cls_class[food_to_category[key]].extend(cls[key])\n",
    "\n",
    "cls_inds = [0 for _ in range(len(cls))]\n",
    "max_n_sample = max([len(samples) for _, samples in cls.items()])\n",
    "for label, samples in cls.items():\n",
    "    if oversample:\n",
    "        pad_size = max_n_sample - len(samples)\n",
    "        cls[label].extend(samples[:pad_size])\n",
    "\n",
    "cls_indicies = list(cls.keys())\n",
    "cls_matcher = {idx: idx for idx in range(len(cls_inds))}\n",
    "\n",
    "if shuffle:\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    for label, indicies in cls.items():\n",
    "        inds = np.array(indicies)\n",
    "        cls[label] = inds[torch.randperm(len(indicies), generator=g).tolist()].tolist()\n",
    "\n",
    "    if epoch != 0:\n",
    "        cls_inds = np.arange(0, len(cls_inds))\n",
    "        cls_inds = cls_inds[torch.randperm(len(cls_inds), generator=g).tolist()]\n",
    "        cls_matcher = {idx: cls_inds[idx] for idx in range(len(cls_inds))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies = []\n",
    "ind_step = cls_indicies[0]\n",
    "for _ in range(len(dset)):\n",
    "    cls_ind = cls_indicies[ind_step % len(cls)]\n",
    "    cls_ind = cls_matcher[cls_ind]\n",
    "    smp_ind = cls_inds[cls_ind] % len(cls[cls_ind])\n",
    "\n",
    "    index = cls[cls_ind][smp_ind]\n",
    "\n",
    "    ind_step += 1\n",
    "    cls_inds[cls_ind] += 1\n",
    "    indicies.append(index)\n",
    "        \n",
    "        # hard negative sampling\n",
    "    cls_index = random.choice(cls[cls_ind])\n",
    "    while index == cls_index:\n",
    "        cls_index = random.choice(cls[cls_ind])\n",
    "    indicies.append(cls_index)\n",
    "            \n",
    "    cls_idx = random.choice(cls_class[food_to_category[cls_ind]])\n",
    "    while index == cls_index or index == cls_idx : \n",
    "        cls_idx = random.choice(cls_class[food_to_category[cls_ind]])\n",
    "    indicies.append(cls_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveSampler(Sampler):\n",
    "    def __init__(self, dset, shuffle: bool = True, seed: int = 42, oversample=False):\n",
    "        self.dset = dset\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.ind_cls = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.cls = {}\n",
    "        self.cls_class = defaultdict(list)\n",
    "        for ind, data in enumerate(self.dset.data):\n",
    "            label = data[\"category_id\"]\n",
    "            if label in self.cls:\n",
    "                self.cls[label].append(ind)\n",
    "            else:\n",
    "                self.cls[label] = [ind]\n",
    "\n",
    "        for key in self.cls.keys():\n",
    "            self.cls_class[food_to_category[key]].extend(self.cls[key])\n",
    "\n",
    "        self.cls_inds = [0 for _ in range(len(self.cls))]\n",
    "        self.max_n_sample = max([len(samples) for _, samples in self.cls.items()])\n",
    "        for label, samples in self.cls.items():\n",
    "            if oversample:\n",
    "                pad_size = self.max_n_sample - len(samples)\n",
    "                self.cls[label].extend(samples[:pad_size])\n",
    "\n",
    "        self.cls_indicies = list(self.cls.keys())\n",
    "        self.cls_matcher = {idx: idx for idx in range(len(self.cls_inds))}\n",
    "\n",
    "        with open(\"./food_id_to_category_id.json\") as f :\n",
    "            self.food_to_category = json.load(f)\n",
    "        \n",
    "        self.food_to_category = {int(k):int(v) for k,v in food_to_category.items()}\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(self.seed)\n",
    "\n",
    "            for label, indicies in self.cls.items():\n",
    "                inds = np.array(indicies)\n",
    "                self.cls[label] = inds[torch.randperm(len(indicies), generator=g).tolist()].tolist()\n",
    "\n",
    "            if self.epoch != 0:\n",
    "                cls_inds = np.arange(0, len(self.cls_inds))\n",
    "                cls_inds = cls_inds[torch.randperm(len(self.cls_inds), generator=g).tolist()]\n",
    "                self.cls_matcher = {idx: cls_inds[idx] for idx in range(len(self.cls_inds))}\n",
    "            self.epoch += 1\n",
    "\n",
    "        indicies = []\n",
    "        pos_indicies = []\n",
    "        neg_indicies = []\n",
    "        self.ind_step = self.cls_indicies[0]\n",
    "        for _ in range(len(self.dset)):\n",
    "            cls_ind = self.cls_indicies[self.ind_step % len(self.cls)]\n",
    "            cls_ind = self.cls_matcher[cls_ind]\n",
    "            smp_ind = self.cls_inds[cls_ind] % len(self.cls[cls_ind])\n",
    "\n",
    "            index = self.cls[cls_ind][smp_ind]\n",
    "\n",
    "            self.ind_step += 1\n",
    "            self.cls_inds[cls_ind] += 1\n",
    "            indicies.append(index)\n",
    "        \n",
    "        # hard negative sampling\n",
    "            cls_index = random.choice(self.cls[cls_ind])\n",
    "            while index == cls_index:\n",
    "                cls_index = random.choice(self.cls[cls_ind])\n",
    "            \n",
    "            cls_idx = random.choice(self.cls_class[self.food_to_category[cls_ind]])\n",
    "            pos_indicies.append(cls_index)\n",
    "\n",
    "            while index == cls_index or cls_ind == self.dset.data[cls_idx][\"category_id\"] : \n",
    "                cls_idx = random.choice(self.cls_class[self.food_to_category[cls_ind]])\n",
    "            \n",
    "            neg_indicies.append(cls_idx)\n",
    "\n",
    "            indicies.extend(pos_indicies)\n",
    "            indicies.extend(neg_indicies)\n",
    "\n",
    "        assert len(indicies) == len(self.dset) * 3\n",
    "        assert len(self.cls) == len(set([self.dset.data[idx][\"category_id\"] for idx in indicies]))\n",
    "        return iter(indicies)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ContrastiveSampler(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = 2 * 3, shuffle=False, sampler = sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokens_path = \"./src/model_configs/tokens_by_length.json\"\n",
    "tokenizer = FoodTokenizer(tokens_path, configs=configs)\n",
    "outputs = []\n",
    "model = build_model(vision_cfg, text_cfg)\n",
    "model.to(device)\n",
    "batch_size = 32\n",
    "outputs_texts = []\n",
    "outputs_images = []\n",
    "\n",
    "for texts , images in train_dataloader :\n",
    "    break\n",
    "    for index in range(0,batch_size * 3, batch_size):\n",
    "        texts = texts[index : index + batch_size]\n",
    "        images = images[index : index + batch_size]\n",
    "        images = images.to(device, dtype=torch.float32)\n",
    "        texts = tokenizer(texts).to(device)\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "\n",
    "        outputs_texts.append(logits_per_text)\n",
    "        outputs_images.append(logits_per_image)\n",
    "        break\n",
    "\n",
    "    logits_per_texts = torch.cat(outputs_texts)\n",
    "    logits_per_images = torch.cat(outputs_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vision_cfg, text_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 3, 224, 224])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('배추겉절이',\n",
       "  '배추겉절이',\n",
       "  '깍두기',\n",
       "  '돼지갈비',\n",
       "  '돼지갈비',\n",
       "  '불고기',\n",
       "  '잡탕밥',\n",
       "  '잡탕밥',\n",
       "  '열무비빔밥',\n",
       "  '오징어젓갈',\n",
       "  '오징어젓갈',\n",
       "  '무장아찌',\n",
       "  '곱창전골',\n",
       "  '곱창전골',\n",
       "  '달걀국',\n",
       "  '내장탕',\n",
       "  '내장탕',\n",
       "  '소고기전골',\n",
       "  '삼선우동',\n",
       "  '삼선우동',\n",
       "  '물만두',\n",
       "  '생선가스',\n",
       "  '생선가스',\n",
       "  '새우튀김',\n",
       "  '고구마맛탕',\n",
       "  '고구마맛탕',\n",
       "  '고추튀김',\n",
       "  '탕수육',\n",
       "  '탕수육',\n",
       "  '닭강정',\n",
       "  '수수부꾸미',\n",
       "  '수수부꾸미',\n",
       "  '찰떡',\n",
       "  '물만두',\n",
       "  '물만두',\n",
       "  '김치라면',\n",
       "  '콩조림',\n",
       "  '콩조림',\n",
       "  '두부고추장조림',\n",
       "  '흑미밥',\n",
       "  '흑미밥',\n",
       "  '해물덮밥',\n",
       "  '단무지무침',\n",
       "  '단무지무침',\n",
       "  '오이생채',\n",
       "  '고추장아찌',\n",
       "  '고추장아찌',\n",
       "  '오이지',\n",
       "  '가지나물',\n",
       "  '가지나물',\n",
       "  '골뱅이무침',\n",
       "  '생연어',\n",
       "  '생연어',\n",
       "  '생선물회',\n",
       "  '두부전',\n",
       "  '두부전',\n",
       "  '호박전',\n",
       "  '치킨데리야끼',\n",
       "  '치킨데리야끼',\n",
       "  '양념왕갈비',\n",
       "  '배추김치',\n",
       "  '배추김치',\n",
       "  '배추겉절이',\n",
       "  '불고기덮밥',\n",
       "  '불고기덮밥',\n",
       "  '제육덮밥',\n",
       "  '숙주나물',\n",
       "  '숙주나물',\n",
       "  '고구마줄기나물',\n",
       "  '두부구이',\n",
       "  '두부구이',\n",
       "  '햄버거스테이크',\n",
       "  '깍두기',\n",
       "  '깍두기',\n",
       "  '파김치',\n",
       "  '소고기메추리알장조림',\n",
       "  '소고기메추리알장조림',\n",
       "  '알감자조림',\n",
       "  '우거지해장국',\n",
       "  '우거지해장국',\n",
       "  '홍합미역국',\n",
       "  '떡국',\n",
       "  '떡국',\n",
       "  '짬뽕라면',\n",
       "  '보리밥',\n",
       "  '보리밥',\n",
       "  '육회비빔밥',\n",
       "  '소고기국밥',\n",
       "  '소고기국밥',\n",
       "  '샐러드김밥',\n",
       "  '라볶이',\n",
       "  '라볶이',\n",
       "  '마파두부',\n",
       "  '오리탕',\n",
       "  '오리탕',\n",
       "  '배추된장국'),\n",
       " tensor([[[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           ...,\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923]],\n",
       " \n",
       "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           ...,\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521]],\n",
       " \n",
       "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           ...,\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802]]],\n",
       " \n",
       " \n",
       "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           ...,\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923]],\n",
       " \n",
       "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           ...,\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521]],\n",
       " \n",
       "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           ...,\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802]]],\n",
       " \n",
       " \n",
       "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7631, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7777, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7777, -1.7923, -1.7923],\n",
       "           ...,\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7777, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7777, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923]],\n",
       " \n",
       "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7371, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7371, -1.7521],\n",
       "           ...,\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7371, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7371, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521]],\n",
       " \n",
       "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4660, -1.4233, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4660, -1.4233, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4660, -1.4376, -1.4802],\n",
       "           ...,\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4518, -1.4660, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4518, -1.4376, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4518, -1.4518, -1.4802]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           ...,\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923]],\n",
       " \n",
       "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           ...,\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521]],\n",
       " \n",
       "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           ...,\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802]]],\n",
       " \n",
       " \n",
       "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           ...,\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923]],\n",
       " \n",
       "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           ...,\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521]],\n",
       " \n",
       "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           ...,\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802]]],\n",
       " \n",
       " \n",
       "         [[[-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           ...,\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923],\n",
       "           [-1.7923, -1.7923, -1.7923,  ..., -1.7923, -1.7923, -1.7923]],\n",
       " \n",
       "          [[-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           ...,\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521],\n",
       "           [-1.7521, -1.7521, -1.7521,  ..., -1.7521, -1.7521, -1.7521]],\n",
       " \n",
       "          [[-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           ...,\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802],\n",
       "           [-1.4802, -1.4802, -1.4802,  ..., -1.4802, -1.4802, -1.4802]]]])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index in range(0,96,32):\n",
    "    batch[index : index + 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
